import * as cron from 'node-cron';
import { scheduledJobsQueue } from '../config/redis.js';
import { QueueStatus, CrawlJob, KeywordDomainPair } from '../types/crawl.js';
import { findAllDomains } from '../repository/mongodb/domainRepository.js';
import { IDomain } from '../models/Domain.js';

export class JobScheduler {
  private readonly CRAWL_TIMES = [9, 12, 15, 18]; // í•œêµ­ì‹œê°„ ê¸°ì¤€

  // í•œêµ­ì‹œê°„ì„ UTC cron í‘œí˜„ì‹ìœ¼ë¡œ ë³€í™˜
  private getCronExpression(koreanHour: number): string {
    const utcHour = (koreanHour - 9 + 24) % 24;
    return `0 ${utcHour} * * *`;
  }

  // URLì—ì„œ ë„ë©”ì¸ ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: www.pknu.ac.kr -> pknu, www.naver.com -> naver)
  private extractDomainName(url: string): string {
    try {
      // URLì—ì„œ í˜¸ìŠ¤íŠ¸ëª… ì¶”ì¶œ
      const urlObj = new URL(url);
      const hostname = urlObj.hostname;
      
      // í˜¸ìŠ¤íŠ¸ëª…ì„ .ìœ¼ë¡œ ë¶„ë¦¬
      const parts = hostname.split('.');
      
      // www.ë¡œ ì‹œì‘í•˜ë©´ ë‘ ë²ˆì§¸ ë¶€ë¶„, ì•„ë‹ˆë©´ ì²« ë²ˆì§¸ ë¶€ë¶„
      if (parts.length >= 2 && parts[0] === 'www' && parts[1]) {
        return parts[1];
      } else if (parts.length >= 1 && parts[0]) {
        return parts[0];
      }
      
      // ê¸°ë³¸ê°’: í˜¸ìŠ¤íŠ¸ëª… ì „ì²´
      return hostname || 'unknown';
    } catch (error) {
      // URL íŒŒì‹± ì‹¤íŒ¨ ì‹œ í˜¸ìŠ¤íŠ¸ëª…ì—ì„œ ì§ì ‘ ì¶”ì¶œ ì‹œë„
      const match = url.match(/\/\/(?:www\.)?([^./]+)/);
      return match && match[1] ? match[1] : 'unknown';
    }
  }

  // í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ ì‹œì‘ -> ì„œë²„ ì‹œì‘í•˜ë©´ ë°”ë¡œ ì‹¤í–‰ë¨
  start(): void {
    console.log('ğŸ”„ ê³µì§€ì‚¬í•­ í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ ì‹œì‘');
    console.log(`ğŸ“… í•œêµ­ì‹œê°„: ${this.CRAWL_TIMES.join('ì‹œ, ')}ì‹œ`);

    this.CRAWL_TIMES.forEach(hour => {
      const cronExpression = this.getCronExpression(hour);
      
      cron.schedule(cronExpression, async () => {
        try {
          // í¬ë¡¤ë§ ì‘ì—…ê°ì²´ ìƒì„±
          const crawlJobs = await this.createCrawlJobs();
          
          // í˜„ì¬ ë‚ ì§œë¥¼ yymmdd í˜•ì‹ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
          const now = new Date();
          const yy = now.getFullYear().toString().slice(-2);
          const mm = String(now.getMonth() + 1).padStart(2, '0');
          const dd = String(now.getDate()).padStart(2, '0');
          const dateStr = `${yy}${mm}${dd}`;
          
          // ê° í¬ë¡¤ë§ ì‘ì—…ê°ì²´ì— ëŒ€í•´ íì— ì‘ì—… ì˜ˆì•½
          for (const crawlJob of crawlJobs) {
            const domainName = this.extractDomainName(crawlJob.url);
            const jobName = `${domainName}-crawl-${dateStr}-${hour}h`;
            
            await scheduledJobsQueue.add(
              jobName,
              {
                jobType: 'crawl-pknu-notices' as const, // TODO: ë™ì  jobTypeìœ¼ë¡œ ë³€ê²½ í•„ìš” ì‹œ ìˆ˜ì •
                url: crawlJob.url,
                scheduledTime: hour,
                timezone: 'Asia/Seoul',
                message: `${domainName} ê³µì§€ì‚¬í•­ í¬ë¡¤ë§`,
                keywordDomainPairs: crawlJob.keywordDomainPairs // í¬ë¡¤ë§ ì‘ì—…ê°ì²´ ì •ë³´ í¬í•¨
              },
              {
                removeOnComplete: 10,
                removeOnFail: 5,
              }
            );
            
            console.log(`[ìŠ¤ì¼€ì¤„] íì— ì‘ì—… ì¶”ê°€: ${jobName} (${crawlJob.url})`);
          }
        } catch (error) {
          console.error(`[ìŠ¤ì¼€ì¤„] í¬ë¡¤ë§ ì‘ì—… ì¶”ê°€ ì‹¤íŒ¨ (${hour}ì‹œ):`, error);
        }
      }, {
        scheduled: true,
        timezone: 'UTC'
      });
    });

    console.log('âœ… í¬ë¡¤ë§ ìŠ¤ì¼€ì¤„ ë“±ë¡ ì™„ë£Œ');
  }

  // ì—¬ëŸ¬ Domainì˜ url_listë¥¼ ëª¨ì•„ì„œ ì¤‘ë³µ ì œê±° í›„ í¬ë¡¤ë§ ì‘ì—…ê°ì²´ ìƒì„±
  async createCrawlJobs(): Promise<CrawlJob[]> {
    try {
      // ëª¨ë“  Domain ì¡°íšŒ
      const domains = await findAllDomains();
      
      // URLì„ í‚¤ë¡œ í•˜ê³ , keywordì™€ domain_id ìŒ ë°°ì—´ì„ ê°’ìœ¼ë¡œ í•˜ëŠ” Map
      const urlMap = new Map<string, KeywordDomainPair[]>();
      
      // ê° Domainì˜ url_listë¥¼ ìˆœíšŒí•˜ë©´ì„œ Mapì— ì¶”ê°€
      for (const domain of domains) {
        const domainId = domain.id;
        
        // ê° Domainì˜ url_listë¥¼ ìˆœíšŒ
        for (const url of domain.url_list) {
          // í•´ë‹¹ urlì— ëŒ€í•œ keywordDomainPairs ë°°ì—´ì´ ì—†ìœ¼ë©´ ìƒì„±
          if (!urlMap.has(url)) {
            urlMap.set(url, []);
          }
          
          // ê° keywordì— ëŒ€í•´ keywordDomainPair ì¶”ê°€
          for (const keyword of domain.keywords) {
            const pairs = urlMap.get(url)!;
            // ì¤‘ë³µ ì²´í¬: ê°™ì€ keywordì™€ domain_id ìŒì´ ì´ë¯¸ ìˆëŠ”ì§€ í™•ì¸
            const exists = pairs.some(
              pair => pair.keyword === keyword && pair.domain_id === domainId
            );
            
            if (!exists) {
              pairs.push({
                keyword,
                domain_id: domainId
              });
            }
          }
        }
      }
      
      // Mapì„ CrawlJob ë°°ì—´ë¡œ ë³€í™˜
      const crawlJobs: CrawlJob[] = Array.from(urlMap.entries()).map(([url, keywordDomainPairs]) => ({
        url,
        keywordDomainPairs
      }));
      
      return crawlJobs;
    } catch (error) {
      console.error('âŒ í¬ë¡¤ë§ ì‘ì—…ê°ì²´ ìƒì„± ì‹¤íŒ¨:', error);
      throw error;
    }
  }

  // í ìƒíƒœ í™•ì¸
  async getQueueStatus(): Promise<QueueStatus | null> {
    try {
      const waiting = await scheduledJobsQueue.getWaiting();
      const active = await scheduledJobsQueue.getActive();
      const completed = await scheduledJobsQueue.getCompleted();
      const failed = await scheduledJobsQueue.getFailed();

      return {
        waiting: waiting.length,
        active: active.length,
        completed: completed.length,
        failed: failed.length
      };
    } catch (error) {
      console.error('í ìƒíƒœ í™•ì¸ ì˜¤ë¥˜:', error);
      return null;
    }
  }
}

